{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pandas import Series,DataFrame\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1), (2, 2), (3, 3), (10, 10), (11, 11), (12, 12)]\n",
      "[1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "X=[(1,1), (2,2), (3, 3), (10,10), (11,11), (12,12)]\n",
    "\n",
    "label=[1,1,1,0,0,0]\n",
    "\n",
    "print(X)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 10, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "x1 = [a_tuple[0] for a_tuple in X]\n",
    "x2 = [a_tuple[0] for a_tuple in X]\n",
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x1,x2, c=label, alpha=0.9, label=\"Two Classes\")\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "\n",
    "# plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0]\n",
      "[[-0.09347047 -0.09347047]]\n",
      "l2\n"
     ]
    }
   ],
   "source": [
    "# Now, let us fit a logistic regression model into this and test it on the train data. \n",
    "# this is using Scikit-learn to check our implementation\n",
    "clf = LogisticRegression(fit_intercept=False, random_state=0).fit(X, label)\n",
    "print(clf.predict(X))\n",
    "clf.score(X, label)\n",
    "print(clf.coef_)\n",
    "\n",
    "print(clf.penalty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|  y|       x|\n",
      "+---+--------+\n",
      "|  1|  [1, 1]|\n",
      "|  1|  [2, 2]|\n",
      "|  1|  [3, 3]|\n",
      "|  0|[10, 10]|\n",
      "|  0|[11, 11]|\n",
      "|  0|[12, 12]|\n",
      "+---+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, array([1, 1])),\n",
       " (1, array([2, 2])),\n",
       " (1, array([3, 3])),\n",
       " (0, array([10, 10])),\n",
       " (0, array([11, 11])),\n",
       " (0, array([12, 12]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us make a RDD in Spark \n",
    "\n",
    "# # Now, we create an RDD from this data. \n",
    "# # X is a numpy array \n",
    "# # y is a simple value lable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "\n",
    "data = {'y':label, 'x':X}\n",
    "\n",
    "df = DataFrame(data)\n",
    "df\n",
    "\n",
    "spark_df_from_pandas = spark.createDataFrame(df, schema=['y', 'x'])\n",
    "spark_df_from_pandas.show()\n",
    "\n",
    "\n",
    "# # Now, we create an RDD from this data. \n",
    "# # X is a numpy array \n",
    "# # y is a simple value lable\n",
    "\n",
    "trainRDD=spark_df_from_pandas.rdd.map(lambda x: (x[0], np.array(x[1]) ))\n",
    "trainRDD.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the cost and gradients \n",
    "# Without using the regulrization factor\n",
    "def llh_cost_gradient(x, coeficients):\n",
    "    \"\"\"\" LLH - loss function and gradiant \"\"\"\n",
    "    theta = np.dot(x[1], coeficients)\n",
    "    \n",
    "    cost = - x[0] * theta + np.log(1 + np.exp(theta))\n",
    "    gradient = - x[1] * x[0] +  x[1] * (np.exp(theta) / (1 + np.exp(theta)))\n",
    "    \n",
    "    return cost, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Regression Coef (Weights): [1. 1.]  Cost (negative LLH) :, 68.14755362647637\n",
      "1 Regression Coef (Weights): [0.94716259 0.94716259]  Cost (negative LLH) :, 64.57295485350909\n",
      "2 Regression Coef (Weights): [0.89540452 0.89540452]  Cost (negative LLH) :, 61.0738764023339\n",
      "3 Regression Coef (Weights): [0.84470742 0.84470742]  Cost (negative LLH) :, 57.649326105723944\n",
      "4 Regression Coef (Weights): [0.79505382 0.79505382]  Cost (negative LLH) :, 54.298406537429074\n",
      "5 Regression Coef (Weights): [0.74642716 0.74642716]  Cost (negative LLH) :, 51.020323747974615\n",
      "6 Regression Coef (Weights): [0.69881194 0.69881194]  Cost (negative LLH) :, 47.81439651173713\n",
      "7 Regression Coef (Weights): [0.6521937 0.6521937]  Cost (negative LLH) :, 44.680065778962614\n",
      "8 Regression Coef (Weights): [0.60655919 0.60655919]  Cost (negative LLH) :, 41.616903976681115\n",
      "9 Regression Coef (Weights): [0.56189641 0.56189641]  Cost (negative LLH) :, 38.62462392019716\n",
      "10 Regression Coef (Weights): [0.51819471 0.51819471]  Cost (negative LLH) :, 35.703087665271504\n",
      "11 Regression Coef (Weights): [0.47544489 0.47544489]  Cost (negative LLH) :, 32.85231727273113\n",
      "12 Regression Coef (Weights): [0.43363933 0.43363933]  Cost (negative LLH) :, 30.0725134864104\n",
      "13 Regression Coef (Weights): [0.3927723 0.3927723]  Cost (negative LLH) :, 27.36409742413589\n",
      "14 Regression Coef (Weights): [0.35284051 0.35284051]  Cost (negative LLH) :, 24.727809835147006\n",
      "15 Regression Coef (Weights): [0.31384445 0.31384445]  Cost (negative LLH) :, 22.16494224136705\n",
      "16 Regression Coef (Weights): [0.27579145 0.27579145]  Cost (negative LLH) :, 19.677851716667295\n",
      "17 Regression Coef (Weights): [0.23870231 0.23870231]  Cost (negative LLH) :, 17.27105145425615\n",
      "18 Regression Coef (Weights): [0.2026252 0.2026252]  Cost (negative LLH) :, 14.953389424683488\n",
      "19 Regression Coef (Weights): [0.16766322 0.16766322]  Cost (negative LLH) :, 12.742046535059677\n",
      "20 Regression Coef (Weights): [0.13402398 0.13402398]  Cost (negative LLH) :, 10.66881067839168\n",
      "21 Regression Coef (Weights): [0.10209428 0.10209428]  Cost (negative LLH) :, 8.786740077950958\n",
      "22 Regression Coef (Weights): [0.0725089 0.0725089]  Cost (negative LLH) :, 7.16865059347226\n",
      "23 Regression Coef (Weights): [0.04610365 0.04610365]  Cost (negative LLH) :, 5.882693721800388\n",
      "24 Regression Coef (Weights): [0.02361569 0.02361569]  Cost (negative LLH) :, 4.948265348165787\n",
      "25 Regression Coef (Weights): [0.00526528 0.00526528]  Cost (negative LLH) :, 4.31682690886922\n",
      "26 Regression Coef (Weights): [-0.00933669 -0.00933669]  Cost (negative LLH) :, 3.9046098041220643\n",
      "27 Regression Coef (Weights): [-0.02088679 -0.02088679]  Cost (negative LLH) :, 3.6351261721792496\n",
      "28 Regression Coef (Weights): [-0.03007858 -0.03007858]  Cost (negative LLH) :, 3.455038543820133\n",
      "29 Regression Coef (Weights): [-0.03747434 -0.03747434]  Cost (negative LLH) :, 3.3311093838896504\n",
      "30 Regression Coef (Weights): [-0.0434959 -0.0434959]  Cost (negative LLH) :, 3.2432588267238818\n",
      "31 Regression Coef (Weights): [-0.04845281 -0.04845281]  Cost (negative LLH) :, 3.1792664789063543\n",
      "32 Regression Coef (Weights): [-0.05257276 -0.05257276]  Cost (negative LLH) :, 3.131521551888461\n",
      "33 Regression Coef (Weights): [-0.05602533 -0.05602533]  Cost (negative LLH) :, 3.0951491242683953\n",
      "34 Regression Coef (Weights): [-0.05893878 -0.05893878]  Cost (negative LLH) :, 3.0669368297983914\n",
      "35 Regression Coef (Weights): [-0.06141172 -0.06141172]  Cost (negative LLH) :, 3.0447104635292814\n",
      "36 Regression Coef (Weights): [-0.06352116 -0.06352116]  Cost (negative LLH) :, 3.0269619758459303\n",
      "37 Regression Coef (Weights): [-0.06532806 -0.06532806]  Cost (negative LLH) :, 3.0126219279893696\n",
      "38 Regression Coef (Weights): [-0.0668813 -0.0668813]  Cost (negative LLH) :, 3.0009166267930887\n",
      "39 Regression Coef (Weights): [-0.06822053 -0.06822053]  Cost (negative LLH) :, 2.991276174180351\n",
      "40 Regression Coef (Weights): [-0.06937822 -0.06937822]  Cost (negative LLH) :, 2.983273907483513\n",
      "41 Regression Coef (Weights): [-0.07038119 -0.07038119]  Cost (negative LLH) :, 2.9765856606271344\n",
      "42 Regression Coef (Weights): [-0.07125176 -0.07125176]  Cost (negative LLH) :, 2.970961822638895\n",
      "43 Regression Coef (Weights): [-0.07200865 -0.07200865]  Cost (negative LLH) :, 2.966207830843532\n",
      "44 Regression Coef (Weights): [-0.07266764 -0.07266764]  Cost (negative LLH) :, 2.9621703298746613\n",
      "45 Regression Coef (Weights): [-0.07324208 -0.07324208]  Cost (negative LLH) :, 2.958727203572455\n",
      "46 Regression Coef (Weights): [-0.07374336 -0.07374336]  Cost (negative LLH) :, 2.955780297007342\n",
      "47 Regression Coef (Weights): [-0.0741812 -0.0741812]  Cost (negative LLH) :, 2.9532500348663664\n",
      "48 Regression Coef (Weights): [-0.07456393 -0.07456393]  Cost (negative LLH) :, 2.9510713949760525\n",
      "49 Regression Coef (Weights): [-0.07489872 -0.07489872]  Cost (negative LLH) :, 2.949190862475708\n",
      "50 Regression Coef (Weights): [-0.07519175 -0.07519175]  Cost (negative LLH) :, 2.9475641019878402\n",
      "51 Regression Coef (Weights): [-0.07544837 -0.07544837]  Cost (negative LLH) :, 2.9461541612398814\n",
      "52 Regression Coef (Weights): [-0.07567321 -0.07567321]  Cost (negative LLH) :, 2.9449300720918594\n",
      "53 Regression Coef (Weights): [-0.07587028 -0.07587028]  Cost (negative LLH) :, 2.9438657515990525\n",
      "54 Regression Coef (Weights): [-0.07604307 -0.07604307]  Cost (negative LLH) :, 2.942939131658961\n",
      "55 Regression Coef (Weights): [-0.07619462 -0.07619462]  Cost (negative LLH) :, 2.9421314643123506\n",
      "56 Regression Coef (Weights): [-0.07632759 -0.07632759]  Cost (negative LLH) :, 2.941426763136177\n",
      "57 Regression Coef (Weights): [-0.07644426 -0.07644426]  Cost (negative LLH) :, 2.9408113509073717\n",
      "58 Regression Coef (Weights): [-0.07654667 -0.07654667]  Cost (negative LLH) :, 2.9402734908781953\n",
      "59 Regression Coef (Weights): [-0.07663657 -0.07663657]  Cost (negative LLH) :, 2.939803084313266\n",
      "60 Regression Coef (Weights): [-0.0767155 -0.0767155]  Cost (negative LLH) :, 2.9393914209058676\n",
      "61 Regression Coef (Weights): [-0.07678482 -0.07678482]  Cost (negative LLH) :, 2.939030971677986\n",
      "62 Regression Coef (Weights): [-0.07684569 -0.07684569]  Cost (negative LLH) :, 2.938715216233301\n",
      "63 Regression Coef (Weights): [-0.07689916 -0.07689916]  Cost (negative LLH) :, 2.9384384979612617\n",
      "64 Regression Coef (Weights): [-0.07694613 -0.07694613]  Cost (negative LLH) :, 2.938195902118995\n",
      "65 Regression Coef (Weights): [-0.07698739 -0.07698739]  Cost (negative LLH) :, 2.937983152745222\n",
      "66 Regression Coef (Weights): [-0.07702364 -0.07702364]  Cost (negative LLH) :, 2.937796525159852\n",
      "67 Regression Coef (Weights): [-0.07705549 -0.07705549]  Cost (negative LLH) :, 2.9376327714288135\n",
      "68 Regression Coef (Weights): [-0.07708348 -0.07708348]  Cost (negative LLH) :, 2.9374890566664935\n",
      "69 Regression Coef (Weights): [-0.07710807 -0.07710807]  Cost (negative LLH) :, 2.9373629044386353\n",
      "70 Regression Coef (Weights): [-0.07712968 -0.07712968]  Cost (negative LLH) :, 2.9372521498394426\n",
      "71 Regression Coef (Weights): [-0.07714867 -0.07714867]  Cost (negative LLH) :, 2.9371548990658805\n",
      "72 Regression Coef (Weights): [-0.07716536 -0.07716536]  Cost (negative LLH) :, 2.937069494512831\n",
      "73 Regression Coef (Weights): [-0.07718002 -0.07718002]  Cost (negative LLH) :, 2.9369944845753966\n",
      "74 Regression Coef (Weights): [-0.07719291 -0.07719291]  Cost (negative LLH) :, 2.936928597477023\n",
      "75 Regression Coef (Weights): [-0.07720424 -0.07720424]  Cost (negative LLH) :, 2.936870718550557\n",
      "76 Regression Coef (Weights): [-0.0772142 -0.0772142]  Cost (negative LLH) :, 2.9368198704885344\n",
      "77 Regression Coef (Weights): [-0.07722295 -0.07722295]  Cost (negative LLH) :, 2.9367751961527717\n",
      "78 Regression Coef (Weights): [-0.07723064 -0.07723064]  Cost (negative LLH) :, 2.936735943594624\n",
      "79 Regression Coef (Weights): [-0.0772374 -0.0772374]  Cost (negative LLH) :, 2.9367014529884488\n",
      "80 Regression Coef (Weights): [-0.07724334 -0.07724334]  Cost (negative LLH) :, 2.9366711452236833\n",
      "81 Regression Coef (Weights): [-0.07724856 -0.07724856]  Cost (negative LLH) :, 2.936644511937077\n",
      "82 Regression Coef (Weights): [-0.07725315 -0.07725315]  Cost (negative LLH) :, 2.936621106797125\n",
      "83 Regression Coef (Weights): [-0.07725719 -0.07725719]  Cost (negative LLH) :, 2.936600537878621\n",
      "84 Regression Coef (Weights): [-0.07726073 -0.07726073]  Cost (negative LLH) :, 2.936582460987309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Regression Coef (Weights): [-0.07726385 -0.07726385]  Cost (negative LLH) :, 2.936566573813377\n",
      "86 Regression Coef (Weights): [-0.07726659 -0.07726659]  Cost (negative LLH) :, 2.936552610808688\n",
      "87 Regression Coef (Weights): [-0.077269 -0.077269]  Cost (negative LLH) :, 2.936540338696429\n",
      "88 Regression Coef (Weights): [-0.07727112 -0.07727112]  Cost (negative LLH) :, 2.936529552533789\n",
      "89 Regression Coef (Weights): [-0.07727298 -0.07727298]  Cost (negative LLH) :, 2.9365200722585247\n",
      "90 Regression Coef (Weights): [-0.07727461 -0.07727461]  Cost (negative LLH) :, 2.9365117396591542\n",
      "91 Regression Coef (Weights): [-0.07727605 -0.07727605]  Cost (negative LLH) :, 2.9365044157162026\n",
      "92 Regression Coef (Weights): [-0.07727732 -0.07727732]  Cost (negative LLH) :, 2.9364979782685743\n",
      "93 Regression Coef (Weights): [-0.07727843 -0.07727843]  Cost (negative LLH) :, 2.936492319964934\n",
      "94 Regression Coef (Weights): [-0.0772794 -0.0772794]  Cost (negative LLH) :, 2.9364873464650088\n",
      "95 Regression Coef (Weights): [-0.07728026 -0.07728026]  Cost (negative LLH) :, 2.936482974860087\n",
      "96 Regression Coef (Weights): [-0.07728102 -0.07728102]  Cost (negative LLH) :, 2.936479132285845\n",
      "97 Regression Coef (Weights): [-0.07728168 -0.07728168]  Cost (negative LLH) :, 2.936475754703955\n",
      "98 Regression Coef (Weights): [-0.07728226 -0.07728226]  Cost (negative LLH) :, 2.9364727858318203\n",
      "99 Regression Coef (Weights): [-0.07728278 -0.07728278]  Cost (negative LLH) :, 2.936470176202366\n"
     ]
    }
   ],
   "source": [
    "num_iteration = 100\n",
    "learning_rate = 0.001\n",
    "coef = np.ones(2) \n",
    "# number of data dimention, feature vector dimention\n",
    "\n",
    "\n",
    "# We want to keep track of the costs so that we can visualize it later. \n",
    "cost_array = []\n",
    "old_cost = 0\n",
    "old_coef = coef\n",
    "\n",
    "reg_lambda = 10\n",
    "\n",
    "for i in range(num_iteration):\n",
    "    \n",
    "    rdd = trainRDD.map(lambda x: (llh_cost_gradient(x, coef)))\n",
    "    result = rdd.reduce(lambda x,y: [x[0] + y[0], x[1] + y[1] ])\n",
    "    \n",
    "    gradient = result[1] + 2 * reg_lambda * coef\n",
    "\n",
    "    cost = result[0] + np.sum(coef)\n",
    "    \n",
    "    print(str(i) + \" Regression Coef (Weights): \"+ str(coef) + \"  Cost (negative LLH) :, \" + str(cost))\n",
    "    \n",
    "    # update the weights \n",
    "    coef = coef - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000249999999792"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4999750000000208"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(-0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " def prediction(x, coef, threshold):\n",
    "        \"\"\"calculate the theta and label with 1 if theta > 0  \"\"\"\n",
    "        theta = np.dot(x[1], coef)\n",
    "        \n",
    "        # Instead of calculating the sigmoid you simply calculate the theta and save computations. \n",
    "        probabilities = sigmoid(theta)\n",
    "        \n",
    "        prediction = 1 if probabilities >= threshold else 0\n",
    "        \n",
    "        return (x[0] , prediction, probabilities, theta,  x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1, 0.4614351354261673, -0.1545664510765309, array([1, 1])),\n",
       " (1, 1, 0.4233264017142462, -0.3091329021530618, array([2, 2])),\n",
       " (1, 1, 0.3861086021960976, -0.46369935322959266, array([3, 3])),\n",
       " (0, 0, 0.1757133298340575, -1.5456645107653089, array([10, 10])),\n",
       " (0, 0, 0.15443510254692605, -1.7002309618418399, array([11, 11])),\n",
       " (0, 0, 0.13531060910954884, -1.8547974129183706, array([12, 12]))]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More info about threshold moving here \n",
    "# https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/\n",
    "\n",
    "rdd_results = trainRDD.map(lambda x: prediction(x, coef, 0.3))\n",
    "rdd_results.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
